<div id="badges">
  <a href="https://www.linkedin.com/in/vasilev-vitalii/">
    <img src="https://img.shields.io/badge/LinkedIn-blue?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn Badge"/>
  </a>
  <a href="https://www.youtube.com/@user-gj9vk5ln5c/featured">
    <img src="https://img.shields.io/badge/YouTube-red?style=for-the-badge&logo=youtube&logoColor=white" alt="Youtube Badge"/>
  </a>
</div>

[English](readme.md)

# mentator-promter

Утилита для пакетной обработки промтов через AI модели (Ollama, OpenAI, Azure OpenAI) с поддержкой шаблонов.

## Описание

**mentator-promter** — это консольный инструмент, который позволяет:
- Отправлять множество промтов в одну или несколько AI моделей
- Использовать шаблоны промтов с файлами данных (payload)
- Автоматически сохранять ответы AI в файлы
- Работать с Ollama, OpenAI и Azure OpenAI

## Возможности

- **Два режима работы**:
  - Прямые промты: отправка промтов в AI как есть
  - Режим шаблонов: замена плейсхолдеров в промтах на содержимое из файлов payload
- **Множественные AI модели**: настройте несколько моделей и отправляйте каждый промт во все из них
- **Динамический размер контекста**: автоматический расчёт оптимального размера контекста на основе длины промта
- **Кэширование на основе хеша**: пропуск обработки файлов, которые не изменились (на основе SHA-256 хеша)
- **Гибкое логирование**: выбор между перезаписью или добавлением в файлы логов
- **Типобезопасная конфигурация**: использует формат JSONC с валидацией схемы

## Установка

```bash
npm install
npm run build:linux  # для Linux
# или
npm run build:win    # для Windows
```

Скомпилированный бинарник будет доступен в директории `dist`.

## Использование

### 1. Генерация шаблона конфигурации

```bash
./mentator-promter --conf-gen /path/to/directory
```

Создаёт файл `mentator-promter.config.TEMPLATE.jsonc` с настройками по умолчанию.

### 2. Редактирование конфигурации

Отредактируйте созданный файл конфигурации, указав:
- Настройки AI моделей (URL, API ключ, имя модели, размер контекста, таймаут)
- Директории для промтов, payload, ответов и логов
- Режим логирования

Пример конфигурации:

```jsonc
{
  "log": {
    "dir": "/path/to/logs",
    "mode": "REWRITE"  // или "APPEND"
  },
  "ai": [
    {
      "url": "http://localhost:11434",
      "model": "deepseek-coder:6.7b",
      "num_ctx": 32768,
      "is_num_ctx_dynamic": true,
      "timeout": 600000
    }
  ],
  "prompt": {
    "dir": "/path/to/prompts",
    "payload": {  // опционально
      "dir": "/path/to/payload",
      "replace": "{{code}}"
    },
    "verify_hash": true  // пропускать файлы, если содержимое не изменилось
  },
  "answer": {
    "dir": "/path/to/answers"
  }
}
```

### 3. Запуск утилиты

```bash
./mentator-promter --conf-use /path/to/your/config.jsonc
```

## Режимы работы

### Режим прямых промтов

Если `payload` не указан в конфигурации:
1. Читает файлы промтов из `prompt.dir`
2. Отправляет каждый промт во все настроенные AI модели
3. Сохраняет ответы в `answer.dir/{файл_промта}/{имя_промта}.answer-{индекс_промта}-{индекс_ai}.txt`

### Режим шаблонов

Если `payload` указан в конфигурации:
1. Читает файлы payload из `prompt.payload.dir`
2. Читает шаблоны промтов из `prompt.dir`
3. Заменяет плейсхолдер (например, `{{code}}`) в промтах на содержимое payload
4. Отправляет каждую комбинацию (payload × промт) во все AI модели
5. Сохраняет ответы в `answer.dir/{файл_payload}/{имя_payload}.answer-{индекс_файла_промта}-{индекс_промта}-{индекс_ai}.txt`

## Формат промтов

Промты используют специальный формат для определения системных и пользовательских сообщений. Подробности см. в [vv-ai-promt-store](https://github.com/VasilevVitalii/vv-ai-promt-store).

Пример файла промта:

```
$$begin
$$system
You are a helpful coding assistant.

$$user
Explain this code:
{{code}}
$$end
```

## Поддержка AI провайдеров

- **Ollama**: `http://localhost:11434` (API ключ не требуется)
- **OpenAI**: `https://api.openai.com/v1` (требуется API ключ)
- **Azure OpenAI**: произвольный endpoint (требуется API ключ)

## Параметры конфигурации

### Настройки AI

- `url`: базовый URL API
- `api_key`: API ключ (опционально для Ollama, обязательно для OpenAI/Azure)
- `model`: имя модели
- `num_ctx`: максимальный размер контекста
- `is_num_ctx_dynamic`: автоматически рассчитывать размер контекста на основе длины промта
- `timeout`: таймаут запроса в миллисекундах

### Промты

- `prompt.dir`: полный путь к директории с файлами промтов
- `prompt.payload.dir`: полный путь к директории с файлами payload (опционально, для режима шаблонов)
- `prompt.payload.replace`: строка-плейсхолдер для замены на содержимое payload (по умолчанию: `{{code}}`)
- `prompt.verify_hash`: пропускать обработку файлов, если хеш содержимого не изменился (по умолчанию: `true`)
  - При включении утилита вычисляет SHA-256 хеш каждого файла и сохраняет его
  - При последующих запусках файлы с неизменённым хешем пропускаются
  - Хеш сохраняется только после успешной обработки всех промтов в файле
  - Это значительно ускоряет повторные запуски, когда изменились только некоторые файлы

### Логирование

- `log.dir`: полный путь к директории логов
- `log.mode`:
  - `REWRITE`: запись лога в `mentator-promter.log` (перезапись при каждом запуске)
  - `APPEND`: запись лога в `mentator-promter.YYYYMMDD-HHMMSS.log` (создание нового файла при каждом запуске)

## Требования

- Node.js 18+ или Bun
- Доступ хотя бы к одному AI провайдеру (Ollama, OpenAI или Azure OpenAI)

## Лицензия

MIT

## Автор

Василий Васильев